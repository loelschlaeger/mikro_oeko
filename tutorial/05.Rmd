---
title: "Aufgabenblatt 5"
author: "Lennart Oelschläger"
email: "lennart.oelschlaeger@uni-bielefeld.de"
date: "`r format(Sys.Date(), format = '%d.%m.%Y')`"
course: "310214 Praktische Übung zu \"Einführung in die Mikroökonometrie\""
term: "Wintersemester 2024/2025"
output: 
  pdf_document:
    template: template.tex
    highlight: null
solution: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  include = rmarkdown::metadata$solution, comment = '#', prompt = TRUE
)
```

## Überblick

In einem *binären Wahlmodell* ist die abhängige Variable binär. Wir modellieren sie nicht direkt, sondern stattdessen die Wahrscheinlichkeit, dass sie den Wert $1$ annimmt (dass sie den Wert $0$ annimmt, folgt dann direkt aus der Gegenwahrscheinlichkeit). Lineare Modelle weisen hier Nachteile auf: Prognosen können negativ sein oder oberhalb von $1$ liegen und es liegt zwangsläufig Heteroskedastizität vor. Als bessere Alternative gibt es *Logit-* und *Probit-Modelle*, sie werden mit der Maximum-Likelihood Methode geschätzt. Mit *ROC* Kurven können die Klassifizierungsgüten verschiedener Modelle verglichen werden.

<!-- Und dann schauen wir uns noch eine neue Datensituation an, nämlich dass die abhängige Variable eine *Zählvariable* ist. In diesem Fall können wir die *Poisson-Regression* verwenden, um Einflüsse zu quantifizieren. -->

## Fortsetzung Aufgabenblatt 4

1. Angenommen, die abhängige Variable $y$ ist nun binär. Welche der Annahmen im klassischen linearen Regressionsmodells gelten dann nicht mehr?

\comment{
\begin{itemize}
  \item MLR.1-4 können weiterhin erfüllt sein
  \item MLR.5 und MLR.6 gelten nicht mehr (siehe Vorlesung)
\end{itemize}
}

2. Welche neue Interpretation bekäme $\hat\beta_1$? 

\comment{
Verändert sich $x$, so verändert sich nicht der (relative) Wert von $y$, sondern die \textbf{Wahrscheinlichkeit}, dass $y = 1$ eintritt. Jedoch sind die Änderungen nicht mehr linear, sodass eine gewohnte ceteris paribus nicht möglich ist und wir andere Methoden (APE, PEA, etc.) benötigen.
}

## Aufgaben

1. Simulieren Sie Daten wie nachfolgend angegeben und schätzen Sie die Probit-Modelle
\begin{align}
\label{eq:model1}
y &= \beta_0 + \beta_1 x_1 + u \\
\label{eq:model2}
y &= \beta_0 + \beta_1 x_1 + \beta_2 x_2 + u
\end{align}
mit der Funktion `glm()`.

```
set.seed(1)
data <- MASS::mvrnorm(n = 50, mu = c(0, 0, 0), Sigma = diag(3))
data <- as.data.frame(data)
colnames(data) <- c("x_1", "x_2", "u")
beta_0 <- 1
beta_1 <- 0.2
beta_2 <- -0.5
y <- beta_0 + data$x_1 * beta_1 + data$x_2 * beta_2 + data$u
data$y <- ifelse(y >= 0.5, 1, 0)
```

```{r, Aufgabe 1 data, include = FALSE}
set.seed(1)
data <- MASS::mvrnorm(n = 50, mu = c(0, 0, 0), Sigma = diag(3))
data <- as.data.frame(data)
colnames(data) <- c("x_1", "x_2", "u")
beta_0 <- 1
beta_1 <- 0.2
beta_2 <- -0.5
y <- beta_0 + data$x_1 * beta_1 + data$x_2 * beta_2 + data$u
data$y <- ifelse(y >= 0.5, 1, 0)
```

```{r, Aufgabe 1}
mod1 <- glm(y ~ x_1, data = data, family = binomial(link = "probit"))
mod2 <- glm(y ~ x_1 + x_2, data = data, family = binomial(link = "probit"))
```

2. Welches der Modelle \eqref{eq:model1} und \eqref{eq:model2} hat die "bessere" Null Deviance beziehungsweise Residual Deviance und was folgt daraus?

```{r, Aufgabe 2}
data.frame(
  "null.deviance" = c(mod1$null.deviance, mod2$null.deviance),
  "residual.deviance" = c(mod1$deviance, mod2$deviance),
  row.names = c("model 1", "model 2")
)
```

\comment{
Je kleiner die Deviance, desto besser beschreibt das Modell die Daten. Die Null Deviance der Modelle ist identisch, denn ohne Regressoren sind beide Modelle identisch. Die Residual Deviance von Modell \eqref{eq:model2} ist kleiner als die von Modell \eqref{eq:model1}, also erklärt Modell \eqref{eq:model2} die Variable $y$ besser als das Modell \eqref{eq:model1}.
}

3. Bitte testen Sie für beide Modelle die Hypothese $H_0 \colon \beta_k = 0, k = 1,\dots,K$ zu $\alpha = 10\%$.

\comment{
Diese Hypothese lässt sich mit der Teststatistik "Null Deviance minus Residual Deviance" testen, die unter der Nullhypothese Chi-Quadrat verteilt ist mit $K$ Freiheitsgraden. Sofern der Wert der Teststatistik größer ist als das $1-\alpha = 90\%$ Quantil der Chi-Quadrat Verteilung mit $K$ Freiheitsgraden, wird die Nullhypothese verworfen.
}

```{r, Aufgabe 3}
# Modell 1: H_0 kann nicht verworfen werden
mod1$null.deviance - mod1$deviance > qchisq(p = 0.9, df = 1) 

# Modell 2: Verwerfe H_0
mod2$null.deviance - mod2$deviance > qchisq(p = 0.9, df = 2)
```

4. Zeichen Sie für beide Modelle die ROC Kurve mit der Funktion `pROC::roc()`. Welches Modell hat demnach die bessere Prognosequalität?

```{r, Aufgabe 4, results = 'hide'}
pROC::roc(
  data$y, pnorm(predict(mod1)), plot = "TRUE", col = "red", quiet = TRUE
)
pROC::roc(
  data$y, pnorm(predict(mod2)), plot = "TRUE", col = "blue", quiet = TRUE,
  add = TRUE
)
```

\comment{
Die blaue Kurve liegt oberhalb der roten Kurve, daher hat das Modell 2 durchgängig die bessere Sensitivität und Spezifität.
}

<!-- 5. Es seien $y_1, \dots, y_n$ unabhängig Poisson verteilt zum Parameter $\lambda > 0$. Zeigen Sie, dass $\bar{y}$ der MLE für $\lambda$ ist. -->

<!-- \comment{ -->
<!-- Siehe \url{https://www.youtube.com/watch?v=Fs4HrXxSFTQ}. -->
<!-- } -->

<!-- 6. Zeigen Sie, dass sowohl der Erwartungswert als auch die Varianz der Poisson-Verteilung jeweils der Parameter $\lambda$ ist. -->

<!-- \comment{ -->
<!-- Siehe \url{https://www.youtube.com/watch?v=RJE2LKBCqy4}. -->
<!-- } -->

<!-- 7. Für gegebene Beobachtungen $y$ und $X$ wollen wir $\lambda = \mathbb{E}(y\mid X)$ als Linearkombination der Regressoren $X$ modellieren. Wie stellen wir sicher, dass $\lambda > 0$ erfüllt bleibt? Wie hoch ist gemäß dieses Modells dann die Wahrscheinlichkeit, dass $y = k$ ist für $k = 0,1,2,\dots$ ? -->

<!-- \comment{ -->
<!-- Wir bilden die Linearkombination $w = \beta_0 + \beta_1 x_{1} + \dots + \beta_K x_{K}$ aus den Regressoren und modellieren $\lambda = \mathbb{E}(y\mid X) = \exp(w)$, siehe Vorlesungsfolien. -->

<!-- Für die Wahrscheinlichkeiten erhalten wir $$\mathbb{P}(y = k \mid X) = \frac{\exp(-\exp(w))\exp(w)^k}{k!}.$$ -->
<!-- } -->

<!-- 8. Nutzen Sie den Datensatz `wooldridge::crime1` und modellieren Sie die Anzahl `narr86` an Inhaftierungen durch das Einkommen `inc86`. Wie können Sie den Einkommenskoeffizienten interpretieren? -->

<!-- ```{r, Aufgabe 8} -->
<!-- glm( -->
<!--   formula = narr86 ~ inc86, -->
<!--   family = "poisson", -->
<!--   data = wooldridge::crime1 -->
<!-- ) -->
<!-- ``` -->

<!-- \comment{ -->
<!-- Der Koeffizient wird als $-0.01$ geschätzt. Die Variable `inc86` ist in der Einheit 100 Dollar angegeben (siehe Dokumentation). Das bedeutet, dass ein Anstieg im Gehalt um 100 Dollar den Erwartungswert an Inhaftierungen um $1\%$ senkt. -->
<!-- } -->
