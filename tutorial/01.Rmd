---
title: "Aufgabenblatt 1"
author: "Lennart Oelschläger"
email: "lennart.oelschlaeger@uni-bielefeld.de"
date: "`r format(Sys.Date(), format = '%d.%m.%Y')`"
course: "310214 Praktische Übung zu \"Einführung in die Mikroökonometrie\""
term: "Wintersemester 2024/2025"
output: 
  pdf_document:
    template: template.tex
    highlight: null
solution: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  include = rmarkdown::metadata$solution, comment = '#', prompt = TRUE
)
```

## Überblick

*Querschnittsdaten* beinhalten Beobachtung der gleichen Variablen von verschiedenen Individuen zu einem Zeitpunkt. Manchmal wird die Datenerhebung parallel an verschiedenen Orten durchgeführt oder zu einem späteren Zeitpunkt wiederholt. Dann ergibt sich eine Sammlung an struktuell gleichen Datensätzen, für die jeweils das gleiche Modell angenommen werden kann. Eine naheliegende Idee ist, anstatt separate Modelle zu schätzen, die Daten in einem *Pool* zusammenzuführen. 

## Aufgaben

1. Wofür kann das folgende Modell eingesetzt werden?
\begin{equation} \label{ausgangsmodell}
wage = \beta_0 + \beta_1 educ + u
\end{equation}

\comment{
Das Modell kann zur Bestimmung des Einflusses der Ausbildungszeit auf den Stundenlohn (wenn $wage$ den Stundenlohn und $educ$ die Ausbildung in Jahren bezeichnet) eingesetzt werden.
}

2. Unter welcher Annahme ist Modell \eqref{ausgangsmodell} korrekt spezifiziert?

\comment{
Das Modell ist korrekt spezifiziert, wenn $E(u\mid wage) = 0$ gilt.
}

3. Mit dem Datensatz `wooldridge::cps78_85` (die `::` Notation bedeutet, dass auf das Objekt `cps78_85` im `R` Paket `wooldridge` zugegriffen wird) kann Modell \eqref{ausgangsmodell} geschätzt werden. Lesen Sie die Daten in `R` ein. Unter `?wooldridge::cps78_85` finden Sie eine Beschreibung.

```{r, Aufgabe 3}
data <- wooldridge::cps78_85
```

4. Die Variable $educ$ ist im Datensatz vorhanden, $wage$ fehlt. Aber wir können die $wage$ Variable aus dem Datensatz konstruieren -- wie?

```{r, Aufgabe 4}
data$wage <- exp(data$lwage)
```

5. Bei dem Datensatz handelt es sich um einen *gepoolten* Datensatz -- warum?

\comment{
Weil der Datensatz Beobachtungen aus zwei unabhängigen Stichproben aus den Jahren 1978 und 1985 mit der gleichen Struktur beinhaltet.
}

6. Verschaffen Sie sich einen Überblick von der (konstruierten) $wage$ und der $educ$ Variable und unterscheiden Sie dabei auch zwischen den beiden Erhebungen. 

```{r, Aufgabe 6}
str(data)

plot(
  data$educ[data$y85 == 0], 
  data$wage[data$y85 == 0], 
  main = "Zusammenhang Ausbildung und Gehalt in 1978 vs. 1985", 
  xlab = "educ (Ausbildungszeit in Jahren)", 
  ylab = "wage (Stundenlohn in USD)",
  xlim = c(0, max(data$educ)),
  ylim = c(0, max(data$wage))
)
points(
  data$educ[data$y85 == 1] + 0.15, 
  data$wage[data$y85 == 1], 
  col = "red"
)
legend(
  "topleft", 
  legend = c("1978", "1985"), 
  col = c(1:2), 
  pch = "o"
)
```

7. Schätzen Sie das *gepoolte Regressionsmodell* in \eqref{ausgangsmodell} und interpretieren Sie die Koeffizienten. Sind die Koeffizienten statistisch signifikant?

```{r, Aufgabe 7}
model <- lm(formula = wage ~ educ, data = data)
summary(model)
```

\comment{
Ein zusätzliches Ausbildungsjahr erhöht den durchschnittlichen Stundenlohn um $\hat\beta_1 = 0.58$ USD. Ohne Ausbildung ($educ = 0$) liegt der Stundenlohn bei durchschnittlich $\hat\beta_0 = 0.17$ USD. Die Konstante ist nicht signifikant (sie sollte dennoch im Modell verbleiben, um den Modellierungsspielraum nicht zu stark einzuschränken). Der Steigungsparameter ist hochsignifikant.
}

8. Überprüfen Sie, ob die Annahme der Homoskedastie verletzt ist.

\comment{
Die Aussagen über die statistische Signifikanz der Schätzungen gilt nur unter dem Vorbehalt homoskedastischer Fehler. Falls diese Annahme verletzt ist, können die regulären Standardfehler nicht für $t$- und $F$-Tests verwendet werden. Um die Homoskedastizität zu überprüfen können wir die Residuen gegen die gefitteten Werte plotten oder formal einen White-Test (oder Breusch-Pagan Test) durchführen.
}

```{r, Aufgabe 8}
plot(
  model$fitted, model$residuals,
  xlab = "angepasste Werte",
  ylab = "Residuen"
)
abline(h = 0)

white <- lm(formula = I(model$residuals^2) ~ model$fitted + I(model$fitted^2))
summary(white)
```

\comment{
Im Plot erkennen wir, dass die Varianz der Residuen mit der Größe der gefitteten Werte ansteigt. Bei dem Test betrachten wir die $F$-Teststatistik. Basierend auf dem $p$-Wert schließen wir, dass wir die Nullhypothese der Homoskedastie verwerfen.
}

9. Welche Auswirkungen hat Heteroskedastie auf die KQ-Schätzung? 

\comment{
Der KQ-Schätzer bleibt unverzerrt und konsistent, das ist erstmal gut. Aber die Schätzung der Standardfehler ist bei Heteroskedastie verzerrt. Und wenn diese Berechnung nicht mehr stimmt, können wir uns auf die $t$- und $F$-Tests sowie Konfidenz- und Prognoseintervalle nicht mehr verlassen. Außerdem ist der KQ-Schätzer dann nicht der BLUS (es gibt also lineare, unverzerrte Schätzer mit geringerer Varianz).
}

10. Wie können wir (hier) mit dem Problem der Heteroskedastie umzugehen?

\comment{
1. Möglichkeit: Variablentransformation, zum Beispiel
\begin{equation*}
\log(wage) = \beta_0 + \beta_1 educ + u
\end{equation*}

2. Möglichkeit: Heteroskedastie-robuste Standardfehler (siehe Vorlesungsfolien)

3. Möglichkeit: (Feasible) Generalised Least Squares (F)GLS Schätzung (ist der BLUS)
}

```{r, Aufgabe 10}
model_log <- lm(formula = lwage ~ educ, data = data)
summary(model_log)

plot(
  model_log$fitted, model_log$residuals,
  xlab = "angepasste Werte (log Modell)",
  ylab = "Residuen (log Modell)"
)
abline(h = 0)

breusch_pagan <- lm(formula = I(model_log$residuals^2) ~ data$educ)
summary(breusch_pagan)

white <- lm(formula = I(model_log$residuals^2) ~ model_log$fitted + I(model_log$fitted^2))
summary(white)
```

11. Schätzen Sie nun ein *log-level Modell*, das für 1985 eine eigene Konstante zulässt:
\begin{equation} \label{dummy_modell}
\log(wage) = \beta_0 + \beta_1 educ + \gamma_0 y85 + u
\end{equation}
Welche Interpretation hat $\gamma_0$? 

```{r, Aufgabe 11}
model_log_dummy <- lm(formula = lwage ~ educ + y85, data = data)
summary(model_log_dummy)
```

\comment{
Im obigen Modell steht $\gamma_0$ für den Niveauunterschied des durchschnittlichen logarithmierten Lohns zwischen den Jahren 1978 und 1985. $\beta_0 + \gamma_0$ gibt also den durchschnittlichen logarithmierten Lohn für das Jahr 1985 für den Fall $educ = 0$ an. In Bezug auf den Lohn selbst erhalten wir die Interpretation als Prozentsatz: es wurde ein um $\hat\gamma_0 = 34.76$ Prozent gestiegenes durchschnittliches Lohnniveau für das Jahr 1985 geschätzt. Vermutlich hat besonders Inflation dafür gesorgt.
}

12. Inkludieren Sie zusätzlich den Interaktionsterm $(y85 \cdot educ)$ in das Modell \eqref{dummy_modell}. Welche Interpretation hat der zugehörige Koeffizient?

\comment{
Wir schätzen das Modell
\begin{equation*}
\log(wage) = \beta_0 + \beta_1 educ + \gamma_0 y85 + \gamma_1 (y85 \cdot educ) + u.
\end{equation*}
}

```{r, Aufgabe 12}
model_log_dummy_interact <- lm(
  formula = lwage ~ educ + y85 + I(y85 * educ), data = data
)
summary(model_log_dummy_interact)
```

\comment{
Interpretation: $\hat\beta_1+ \hat\gamma_1$ steht für die prozentuale Veränderung des mittleren Lohns auf eine Veränderung von $educ$ um eine Einheit für das Jahr 1985. Damit gibt $\gamma_1$ also den Unterschied im Steigungsparameter zwischen 1978 und 1985 an. Anscheinend zahlt sich Bildung in 1985 mehr aus als es noch in 1978 der Fall war.
}

13. Wenn Sie das Modell
\begin{equation} \label{log_modell}
\log(wage) = \beta_0 + \beta_1 educ + u
\end{equation}
einmal für den gepoolten Datensatz und dann für die Daten aus 1978 und 1985 getrennt schätzen, welche Unterschiede in den Koeffizienten und Varianzen erwarten Sie dann?

\comment{
Wir erwarten (leichte) Unterschiede in den geschätzten Koeffizienten und geringere Standardabweichungen für die geschätzten Koeffizienten im gepoolten Modell. Das können wir überprüfen:
}

```{r, Aufgabe 13}
model_pool <- lm(formula = lwage ~ educ, data = data)
summary(model_pool)
model_1978 <- lm(formula = lwage ~ educ, data = data, subset = (y85 == 0))
summary(model_1978)
model_1985 <- lm(formula = lwage ~ educ, data = data, subset = (y85 == 1))
summary(model_1985)
```

14. Die Daten sollten nur gepoolt werden, wenn sich die Koeffizienten der einzelnen Stichproben nicht signifikant voneinander unterscheiden. Bitte führen Sie einen Chow-Test durch, um die Gleichheit der Koeffizienten zu testen.

\comment{
Der Chow-Test:

- Nullhypothese: die Koeffizienten der einzelnen Stichproben sind gleich

- Gegenhypothese: mindestens ein Koeffizient unterscheidet sich

- Teststatistik: $\displaystyle F = \frac{SSR_\text{pool} - (SSR_{1978} + SSR_{1985})}{SSR_{1978} + SSR_{1985}} \cdot \frac{n_{1978} + n_{1985} - 2(K+1)}{K + 1}$, wobei $SSR_\text{pool}$, $SSR_{1978}$ und $SSR_{1978}$ die Residuenquadratsumme des gepoolten Modells und der getrennten Modelle, $n_{1978}$ und $n_{1985}$ die Stichprobengröße in den getrennten Modellen und $K$ die Anzahl Modellparameter (ohne Achsenabschnitt) ist.

- Ablehnung zum Signifikanzniveau $\alpha$: wenn die Teststatistik $F$ größer ist als das $1-\alpha$ Quantil der $F$-Verteilung mit $K+1$ und $n_{1978} + n_{1985} - 2(K+1)$ Freiheitsgraden
}

```{r, Aufgabe 14}
### Teststatistik berechnen
SSR_pool <- sum(model_pool$residuals^2)
SSR_1978 <- sum(model_1978$residuals^2)
SSR_1985 <- sum(model_1985$residuals^2) 
n_1978 <- nobs(model_1978)
n_1985 <- nobs(model_1985)
K <- 1
F <- (SSR_pool - (SSR_1978 + SSR_1985)) / (SSR_1978 + SSR_1985) * 
  (n_1978 + n_1985 - 2 * (K + 1)) / (K + 1)

### Testdurchführung
alpha <- 0.05
quantil <- qf(1- alpha, K + 1, n_1978 + n_1985 - 2 * (K + 1))
F > quantil

### alternativ mit p-value
pvalue <- 1 - pf(F, K + 1, n_1978 + n_1985 - 2 * (K + 1))
pvalue > alpha
```

\comment{
In diesem Fall wird die Nullhypothese verworfen. Wir folgern, dass ein Poolen der Daten nicht vorgenommen werden sollte, da sich die Koeffizienten statistisch signifikant voneinander unterscheiden.
}

15. Der Chow-Test basiert auf der Annahme, dass in beiden Datensätzen die Fehlervarianz identisch sind. Wenn das nicht der Fall ist, gibt es trotzdem eine Möglichkeit, diesen Test anzuwenden -- welche?

\comment{
Statt der OLS Schätzer nehme die (F)GLS Schätzer.
}

