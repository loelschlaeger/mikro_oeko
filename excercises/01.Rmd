---
title: "Aufgabenblatt 1"
author: "Lennart Oelschläger"
email: "lennart.oelschlaeger@uni-bielefeld.de"
date: "`r format(Sys.Date(), format = '%d.%m.%Y')`"
course: "310214 Praktische Übung zu \"Einführung in die Mikroökonometrie\""
term: "Wintersemester 2023/2024"
output: 
  pdf_document:
    template: template.tex
    highlight: null
solution: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  include = rmarkdown::metadata$solution, comment = '#', prompt = TRUE
)
```

## Überblick

*Querschnittsdaten* beinhalten Beobachtung der gleichen Variablen von verschiedenen Individuen zu einem Zeitpunkt. Manchmal wird die Datenerhebung parallel an verschiedenen Orten durchgeführt oder zu einem späteren Zeitpunkt wiederholt. Dann ergibt sich eine Sammlung an struktuell gleichen Datensätzen, für die jeweils das gleiche Modell angenommen werden kann. Eine naheliegende Idee ist, anstatt separate Modelle zu schätzen, die Daten in einem *Pool* zusammenzuführen. 

## Aufgaben

1. Wofür kann das folgende Modell eingesetzt werden?
\begin{equation} \label{ausgangsmodell}
wage = \beta_0 + \beta_1 educ + u
\end{equation}

\comment{
Das Modell kann zur Bestimmung des Einflusses der Ausbildungszeit auf den Stundenlohn (wenn $wage$ den Stundenlohn und $educ$ die Ausbildung in Jahren bezeichnet) eingesetzt werden.
}

2. Unter welcher Annahme ist Modell \eqref{ausgangsmodell} korrekt spezifiziert?

\comment{
Das Modell ist korrekt spezifiziert, wenn $E(u\mid wage) = 0$ gilt.
}

3. Mit dem Datensatz `wooldridge::cps78_85` (die `::` Notation bedeutet, dass auf das Objekt `cps78_85` im `R` Paket `wooldridge` zugegriffen wird) kann Modell \eqref{ausgangsmodell} geschätzt werden. Lesen Sie die Daten in `R` ein. Unter `?wooldridge::cps78_85` finden Sie eine Beschreibung.

```{r, Aufgabe 3}
data <- wooldridge::cps78_85
```

4. Die Variable $educ$ ist im Datensatz vorhanden, $wage$ fehlt. Aber wir können die $wage$ Variable aus dem Datensatz konstruieren -- wie?

```{r, Aufgabe 4}
data$wage <- exp(data$lwage)
```

5. Bei dem Datensatz handelt es sich um einen *gepoolten* Datensatz -- warum?

\comment{
Weil der Datensatz Beobachtungen aus zwei unabhängigen Stichproben aus den Jahren 1978 und 1985 mit der gleichen Struktur beinhaltet.
}

6. Verschaffen Sie sich einen Überblick von der (konstruierten) $wage$ und der $educ$ Variable und unterscheiden Sie dabei auch zwischen den beiden Erhebungen. 

```{r, Aufgabe 6}
str(data)

plot(
  data$educ[data$y85 == 0], 
  data$wage[data$y85 == 0], 
  main = "Zusammenhang Ausbildung und Gehalt in 1978 vs. 1985", 
  xlab = "educ (Ausbildungszeit in Jahren)", 
  ylab = "wage (Stundenlohn in USD)",
  xlim = c(0, max(data$educ)),
  ylim = c(0, max(data$wage))
)
points(
  data$educ[data$y85 == 1] + 0.15, 
  data$wage[data$y85 == 1], 
  col = "red"
)
legend(
  "topleft", 
  legend = c("1978", "1985"), 
  col = c(1:2), 
   pch = "o"
)
```

7. Schätzen Sie das *gepoolte Regressionsmodell* in \eqref{ausgangsmodell} und interpretieren Sie die Koeffizienten. Sind die Koeffizienten statistisch signifikant?

```{r, Aufgabe 7}
model <- lm(formula = wage ~ educ, data = data)
summary(model)
```

\comment{
Ein zusätzliches Ausbildungsjahr erhöht den durchschnittlichen Stundenlohn um $\hat\beta_1 = 0.58$ USD. Ohne Ausbildung ($educ = 0$) liegt der Stundenlohn bei durchschnittlich $\hat\beta_0 = 0.17$ USD. Die Konstante ist nicht signifikant (sie sollte dennoch im Modell verbleiben, um den Modellierungsspielraum nicht zu stark einzuschränken). Der Steigungsparameter ist hochsignifikant.
}

8. Überprüfen Sie, ob die Annahme der Homoskedastie verletzt ist.

\comment{
Die Aussagen über die statistische Signifikanz der Schätzungen gilt nur unter dem Vorbehalt homoskedastischer Fehler. Falls diese Annahme verletzt ist, können die regulären Standardfehler nicht für $t$- und $F$-Tests verwendet werden. Um die Homoskedastizität zu überprüfen können wir die Residuen gegen die gefitteten Werte plotten oder formal einen White-Test (oder Breusch-Pagan Test) durchführen.
}

```{r, Aufgabe 8}
plot(
  model$fitted, model$residuals,
  xlab = "angepasste Werte",
  ylab = "Residuen"
)
abline(h = 0)

white <- lm(formula = I(model$residuals^2) ~ model$fitted + I(model$fitted^2))
summary(white)
```

\comment{
Im Plot erkennen wir, dass die Varianz der Residuen mit der Größe der gefitteten Werte ansteigt. Bei dem Test betrachten wir die $F$-Teststatistik. Basierend auf dem $p$-Wert schließen wir, dass wir die Nullhypothese der Homoskedastie verwerfen.
}

9. Welche Auswirkungen hat Heteroskedastie auf die KQ-Schätzung? 

\comment{
Der KQ-Schätzer bleibt unverzerrt und konsistent, das ist erstmal gut. Aber die Schätzung der Standardfehler ist bei Heteroskedastie verzerrt. Und wenn diese Berechnung nicht mehr stimmt, können wir uns auf die $t$- und $F$-Tests sowie Konfidenz- und Prognoseintervalle nicht mehr verlassen. Außerdem ist der KQ-Schätzer dann nicht der BLUS (es gibt also lineare, unverzerrte Schätzer mit geringerer Varianz).
}

10. Wie können wir (hier) mit dem Problem der Heteroskedastie umzugehen?

\comment{
1. Möglichkeit: Variablentransformation, zum Beispiel
\begin{equation*}
\log(wage) = \beta_0 + \beta_1 educ + u
\end{equation*}

2. Möglichkeit: Heteroskedastie-robuste Standardfehler (siehe Vorlesungsfolien)

3. Möglichkeit: (Feasible) Generalised Least Squares (F)GLS Schätzung (ist der BLUS)
}

```{r, Aufgabe 10}
model_log <- lm(formula = lwage ~ educ, data = data)
summary(model_log)

plot(
  model_log$fitted, model_log$residuals,
  xlab = "angepasste Werte (log Modell)",
  ylab = "Residuen (log Modell)"
)
abline(h = 0)

breusch_pagan <- lm(formula = I(model_log$residuals^2) ~ data$educ)
summary(breusch_pagan)

white <- lm(formula = I(model_log$residuals^2) ~ model_log$fitted + I(model_log$fitted^2))
summary(white)
```

11. Schätzen Sie nun ein *log-level Modell*, das für 1985 eine eigene Konstante zulässt:
\begin{equation} \label{dummy_modell}
\log(wage) = \beta_0 + \beta_1 educ + \gamma_0 y85 + u
\end{equation}
Welche Interpretation hat $\gamma_0$? 

```{r, Aufgabe 11}
model_log_dummy <- lm(formula = lwage ~ educ + y85, data = data)
summary(model_log_dummy)
```

\comment{
Im obigen Modell steht $\gamma_0$ für den Niveauunterschied des durchschnittlichen logarithmierten Lohns zwischen den Jahren 1978 und 1985. $\beta_0 + \gamma_0$ gibt also den durchschnittlichen logarithmierten Lohn für das Jahr 1985 für den Fall $educ = 0$ an. In Bezug auf den Lohn selbst erhalten wir die Interpretation als Prozentsatz: es wurde ein um $\hat\gamma_0 = 34.76$ Prozent gestiegenes durchschnittliches Lohnniveau für das Jahr 1985 geschätzt. Vermutlich hat besonders Inflation dafür gesorgt.
}

12. Inkludieren Sie zusätzlich den Interaktionsterm $(y85 \cdot educ)$ in das Modell \eqref{dummy_modell}. Welche Interpretation hat der zugehörige Koeffizient?

\comment{
Wir schätzen das Modell
\begin{equation*}
\log(wage) = \beta_0 + \beta_1 educ + \gamma_0 y85 + \gamma_1 (y85 \cdot educ) + u.
\end{equation*}
}

```{r, Aufgabe 12}
model_log_dummy_interact <- lm(
  formula = lwage ~ educ + y85 + I(y85 * educ), data = data
)
summary(model_log_dummy_interact)
```

\comment{
Interpretation: $\hat\beta_1+ \hat\gamma_1$ steht für die prozentuale Veränderung des mittleren Lohns auf eine Veränderung von $educ$ um eine Einheit für das Jahr 1985. Damit gibt $\gamma_1$ also den Unterschied im Steigungsparameter zwischen 1978 und 1985 an. Anscheinend zahlt sich Bildung in 1985 mehr aus als es noch in 1978 der Fall war.
}


